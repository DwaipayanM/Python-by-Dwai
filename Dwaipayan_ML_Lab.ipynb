{
 "cells": [
  {
   "cell_type": "code",
   "id": "a157055a-93ba-48a7-9cf9-22f0080682a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T17:11:40.130399Z",
     "start_time": "2025-06-14T17:10:37.675200Z"
    }
   },
   "source": "pip install --upgrade pip",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\debroop_python\\.venv\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T17:30:11.691475Z",
     "start_time": "2025-06-14T17:30:09.929149Z"
    }
   },
   "cell_type": "code",
   "source": "pip install ipynb-py-convert",
   "id": "4245e52131e2f1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb-py-convert in c:\\debroop_python\\.venv\\lib\\site-packages (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8bfc7ce9-fd8d-4015-9142-33806cc7f2f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T17:37:14.204092Z",
     "start_time": "2025-06-14T17:35:05.111435Z"
    }
   },
   "source": [
    "#ipynb-py-convert Python.py Python1.ipynb\n",
    "%pip install jupytext\n",
    "!jupytext --to notebook Python.py"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupytext\n",
      "  Downloading jupytext-1.17.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting markdown-it-py>=1.0 (from jupytext)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdit-py-plugins (from jupytext)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: nbformat in c:\\debroop_python\\.venv\\lib\\site-packages (from jupytext) (5.10.4)\n",
      "Requirement already satisfied: packaging in c:\\debroop_python\\.venv\\lib\\site-packages (from jupytext) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\debroop_python\\.venv\\lib\\site-packages (from jupytext) (6.0.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=1.0->jupytext)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\debroop_python\\.venv\\lib\\site-packages (from nbformat->jupytext) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\debroop_python\\.venv\\lib\\site-packages (from nbformat->jupytext) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\debroop_python\\.venv\\lib\\site-packages (from nbformat->jupytext) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\debroop_python\\.venv\\lib\\site-packages (from nbformat->jupytext) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\debroop_python\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\debroop_python\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\debroop_python\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\debroop_python\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\debroop_python\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\debroop_python\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (310)\n",
      "Downloading jupytext-1.17.2-py3-none-any.whl (164 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, mdit-py-plugins, jupytext\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [markdown-it-py]\n",
      "   ---------- ----------------------------- 1/4 [markdown-it-py]\n",
      "   ---------- ----------------------------- 1/4 [markdown-it-py]\n",
      "   ---------- ----------------------------- 1/4 [markdown-it-py]\n",
      "   -------------------- ------------------- 2/4 [mdit-py-plugins]\n",
      "   -------------------- ------------------- 2/4 [mdit-py-plugins]\n",
      "   ------------------------------ --------- 3/4 [jupytext]\n",
      "   ------------------------------ --------- 3/4 [jupytext]\n",
      "   ------------------------------ --------- 3/4 [jupytext]\n",
      "   ------------------------------ --------- 3/4 [jupytext]\n",
      "   ---------------------------------------- 4/4 [jupytext]\n",
      "\n",
      "Successfully installed jupytext-1.17.2 markdown-it-py-3.0.0 mdit-py-plugins-0.4.2 mdurl-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[jupytext] Reading Python.py in format py\n",
      "[jupytext] Writing Python.ipynb\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f6da5678-f267-4db9-81f2-66c76c9f4ade",
   "metadata": {},
   "source": [
    "pip install langchain openai"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fac2b70-b416-4e31-a8a1-4aace949821f",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION USING PYTHON LIBRARIES - Import Python Libraries for \n",
    "# Data Handling (pandas, numpy), \n",
    "# Data Visualization and Representation (matplotlib) \n",
    "# and building Machine Learning Models (sklearn)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b11940c8-be23-400c-b5eb-43572a07ddd4",
   "metadata": {},
   "source": [
    "#Load and Preview the data in the dataset Headbrain.csv into a Pandas Dataframe for analysis and modelling\n",
    "\n",
    "df = pd.read_csv(\"Headbrain.csv\")\n",
    "df.head(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3527ad5a-93e8-47c9-b929-bad8905fd73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T10:55:08.860283Z",
     "iopub.status.busy": "2025-05-01T10:55:08.859727Z",
     "iopub.status.idle": "2025-05-01T10:55:08.863807Z",
     "shell.execute_reply": "2025-05-01T10:55:08.863216Z",
     "shell.execute_reply.started": "2025-05-01T10:55:08.860260Z"
    }
   },
   "source": [
    "#Display the number of records (rows)) and features(columns) to understand the size and dimension of the dataset\n",
    "\n",
    "print(f\"Number of records/rows: {df.shape[0]}\")\n",
    "print(f\"Number of features/columns:{df.shape[1]}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6b20347-3ee7-4a38-acbc-b5e9cb7f43e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T10:55:13.202873Z",
     "iopub.status.busy": "2025-05-01T10:55:13.202572Z",
     "iopub.status.idle": "2025-05-01T10:55:13.206525Z",
     "shell.execute_reply": "2025-05-01T10:55:13.205809Z",
     "shell.execute_reply.started": "2025-05-01T10:55:13.202851Z"
    }
   },
   "source": [
    "# Prepare features and Labels to extract the Independent Variable (Head size) and dependent variable (Brain Weights)\n",
    "# Reshape the feature array to be compatible for Machine Learning Model Training\n",
    "\n",
    "x = df[\"Head size\"].values\n",
    "m = len(x)\n",
    "x = x.reshape((m,-1))\n",
    "y = df[\"Brain Weights\"].values\n",
    "#print(f\"x= {x}\")\n",
    "#print(f\"y= {y}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7434f825-7970-4fbf-aa17-cf84d8d8d4a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T10:55:21.262778Z",
     "iopub.status.busy": "2025-05-01T10:55:21.262471Z",
     "iopub.status.idle": "2025-05-01T10:55:21.269740Z",
     "shell.execute_reply": "2025-05-01T10:55:21.269099Z",
     "shell.execute_reply.started": "2025-05-01T10:55:21.262756Z"
    }
   },
   "source": [
    "# Train-Test split the dataset train a Linear Regression model using the training set\n",
    "# Evaluate the model performance by calculating the R2 score\n",
    "\n",
    "regmodel = linear_model.LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "regmodel.fit(x_train,y_train)\n",
    "r2=regmodel.score(x_test,y_test)\n",
    "print(r2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae495e48-d3c9-43d8-96b8-b533144ac6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T10:55:26.165061Z",
     "iopub.status.busy": "2025-05-01T10:55:26.164759Z",
     "iopub.status.idle": "2025-05-01T10:55:26.170835Z",
     "shell.execute_reply": "2025-05-01T10:55:26.170285Z",
     "shell.execute_reply.started": "2025-05-01T10:55:26.165039Z"
    }
   },
   "source": [
    "# Train Linear Regression on Full Dataset and check R2 score\n",
    "\n",
    "regmodel = linear_model.LinearRegression()\n",
    "regmodel.fit(x,y)\n",
    "r2=regmodel.score(x,y)\n",
    "print(r2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4857bd8-3b53-48d1-8cca-245536ffdb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T12:26:28.631610Z",
     "iopub.status.busy": "2025-05-01T12:26:28.631366Z",
     "iopub.status.idle": "2025-05-01T12:26:28.634962Z",
     "shell.execute_reply": "2025-05-01T12:26:28.634390Z",
     "shell.execute_reply.started": "2025-05-01T12:26:28.631591Z"
    }
   },
   "source": [
    "# LINEAR REGRESSION USING MATHS - # Import Python Libraries for \n",
    "# Data Handling (pandas, numpy), \n",
    "# Data Visualization and Representation (matplotlib) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c40031e2-a9b0-458a-98b0-48e94f25d5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T12:28:35.265398Z",
     "iopub.status.busy": "2025-05-01T12:28:35.264772Z",
     "iopub.status.idle": "2025-05-01T12:28:35.272478Z",
     "shell.execute_reply": "2025-05-01T12:28:35.271697Z",
     "shell.execute_reply.started": "2025-05-01T12:28:35.265367Z"
    }
   },
   "source": [
    "# Using the (Head size) and (Brain Weights) columns from the dataset,\n",
    "# manually compute the Slope (m) and Intercept (c) to derive the best-fit line \n",
    "# using the formulas for simple linear regression (without using any Machine learning libraries)\n",
    "\n",
    "# Prepare the data to calculate the mean of X & Y\n",
    "x = df[\"Head size\"].values\n",
    "y = df[\"Brain Weights\"].values\n",
    "\n",
    "# Calculate total number of values\n",
    "val = len(x)\n",
    "mean_x = np.mean(x)\n",
    "mean_y = np.mean(y)\n",
    "\n",
    "# Calculate the Slope(m) and Intercept(c) using the Formulas\n",
    "# Numerator\n",
    "num = 0 \n",
    "# Denominator\n",
    "den = 0 \n",
    "\n",
    "for i in range(val):\n",
    "    num += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "    den += (x[i] - mean_x) ** 2\n",
    "\n",
    "m = num / den\n",
    "c = mean_y - (m * mean_x)\n",
    "print(m, c)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "981adf09-8232-4534-8505-b2cdba2c09c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T12:34:14.806312Z",
     "iopub.status.busy": "2025-05-01T12:34:14.805983Z",
     "iopub.status.idle": "2025-05-01T12:34:15.050640Z",
     "shell.execute_reply": "2025-05-01T12:34:15.049757Z",
     "shell.execute_reply.started": "2025-05-01T12:34:14.806291Z"
    }
   },
   "source": [
    "# Generate a visual representation of the regression model by plotting:\n",
    "# • The scatter plot of the original data points (Head size vs. Brain Weights).\n",
    "# • The regression line based on the calculated slope and intercept.\n",
    "\n",
    "max_x = np.max(x)\n",
    "min_x = np.min(x)\n",
    "x1 = np.linspace(min_x, max_x, 500)\n",
    "y1 = c + m * x1\n",
    "\n",
    "\n",
    "# Plot the Regression Line\n",
    "plt.plot(x1, y1, color='#380BB5', label='Regression Line')\n",
    "\n",
    "# Plotting the Scatter Points\n",
    "plt.scatter(x, y, c='#0FB907', label='Scatter Plot')\n",
    "plt.xlabel('Head Size in Cubic Centimeter')\n",
    "plt.ylabel('Brain Weight in grams')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26f38b5f-3950-462f-a217-d055261da3d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T12:29:44.708027Z",
     "iopub.status.busy": "2025-05-01T12:29:44.707725Z",
     "iopub.status.idle": "2025-05-01T12:29:44.712654Z",
     "shell.execute_reply": "2025-05-01T12:29:44.712095Z",
     "shell.execute_reply.started": "2025-05-01T12:29:44.708006Z"
    }
   },
   "source": [
    "# Compute the coefficient of determination (R² score) to evaluate the Model Performance i.e. \n",
    "# how well the regression line fits the data. \n",
    "#The R² score should be calculated using the total sum of squares and the regression sum of squares.'\n",
    "\n",
    "ssq_t = 0\n",
    "ssq_r = 0\n",
    "val = len(x)\n",
    "\n",
    "for i in range(val):\n",
    "    y_pred = c+m*(x[i]) \n",
    "    ssq_t += (y[i] - mean_y)**2\n",
    "    ssq_r += (y_pred-mean_y)**2\n",
    "r2 = ssq_r/ssq_t\n",
    "print(r2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e08eab46-92c9-4d19-92da-b19fd822cef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:23:33.460188Z",
     "iopub.status.busy": "2025-05-01T13:23:33.459769Z",
     "iopub.status.idle": "2025-05-01T13:23:33.463785Z",
     "shell.execute_reply": "2025-05-01T13:23:33.463216Z",
     "shell.execute_reply.started": "2025-05-01T13:23:33.460149Z"
    }
   },
   "source": [
    "# Develop a Decision Tree classification model:\n",
    "    # Load and explore the dataset to understand its structure and preprocess as needed.\n",
    "    # Split the data into training and testing sets.\n",
    "    # Train the Decision Tree classifier.\n",
    "    # Evaluate the model's performance using metrics like accuracy, precision, recall, and a confusion matrix.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f1364e6-1e2a-4cab-ae84-5bf297cb449a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:23:37.479975Z",
     "iopub.status.busy": "2025-05-01T13:23:37.479663Z",
     "iopub.status.idle": "2025-05-01T13:23:37.488880Z",
     "shell.execute_reply": "2025-05-01T13:23:37.488396Z",
     "shell.execute_reply.started": "2025-05-01T13:23:37.479954Z"
    }
   },
   "source": [
    "#Load and Preview the data in the dataset Purchase.csv into a Pandas Dataframe for analysis and modelling\n",
    "\n",
    "df = pd.read_csv(\"Purchase.csv\")\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "42153df2-8522-4a9d-91ea-1b714aaabcd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:23:43.591226Z",
     "iopub.status.busy": "2025-05-01T13:23:43.590924Z",
     "iopub.status.idle": "2025-05-01T13:23:43.594780Z",
     "shell.execute_reply": "2025-05-01T13:23:43.594140Z",
     "shell.execute_reply.started": "2025-05-01T13:23:43.591204Z"
    }
   },
   "source": [
    "#Display the number of records (rows)) and features(columns) to understand the size and dimension of the dataset\n",
    "\n",
    "print(f\"Number of records/rows: {df.shape[0]}\")\n",
    "print(f\"Number of features/columns:{df.shape[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "507a2bd3-1d9c-460e-b6d4-1f92cb891579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:23:47.316851Z",
     "iopub.status.busy": "2025-05-01T13:23:47.316264Z",
     "iopub.status.idle": "2025-05-01T13:23:47.320877Z",
     "shell.execute_reply": "2025-05-01T13:23:47.320238Z",
     "shell.execute_reply.started": "2025-05-01T13:23:47.316823Z"
    }
   },
   "source": [
    "# Prepare the dataset for machine learning by splitting it into features and target variables.\n",
    "# Reshape the feature array to be compatible for Machine Learning Model Training\n",
    "# Separate the Input Variable (x), Output Variable (y) and Date\n",
    "x = df.drop(['User ID', 'Purchased'], axis =1)\n",
    "y = df['Purchased']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf930e9c-7ea6-4e15-9434-b4b90a73eb30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:23:55.364821Z",
     "iopub.status.busy": "2025-05-01T13:23:55.364477Z",
     "iopub.status.idle": "2025-05-01T13:23:55.370639Z",
     "shell.execute_reply": "2025-05-01T13:23:55.370049Z",
     "shell.execute_reply.started": "2025-05-01T13:23:55.364798Z"
    }
   },
   "source": [
    "#Convert labels to Number by using a labelencoder to convert gender column into Numeric Values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_gender = LabelEncoder()\n",
    "\n",
    "x['Gender_n'] = le_gender.fit_transform(x['Gender'])\n",
    "print(x.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9114e4e1-68a4-4362-848b-5ed0b3d0ce36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:24:11.635777Z",
     "iopub.status.busy": "2025-05-01T13:24:11.635443Z",
     "iopub.status.idle": "2025-05-01T13:24:11.641236Z",
     "shell.execute_reply": "2025-05-01T13:24:11.640690Z",
     "shell.execute_reply.started": "2025-05-01T13:24:11.635749Z"
    }
   },
   "source": [
    "#Drop the Original Gender Column\n",
    "x.drop('Gender', axis=1, inplace=True)\n",
    "print(x.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "765eab90-efca-41ff-9f21-3938ca0d7af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:31:57.138466Z",
     "iopub.status.busy": "2025-05-01T13:31:57.138159Z",
     "iopub.status.idle": "2025-05-01T13:31:57.143343Z",
     "shell.execute_reply": "2025-05-01T13:31:57.142732Z",
     "shell.execute_reply.started": "2025-05-01T13:31:57.138445Z"
    }
   },
   "source": [
    "# Split the data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=100)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3640d9d1-4a90-4cee-bfdf-fee5f8f8a387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:33:41.462726Z",
     "iopub.status.busy": "2025-05-01T13:33:41.462389Z",
     "iopub.status.idle": "2025-05-01T13:33:41.470801Z",
     "shell.execute_reply": "2025-05-01T13:33:41.470237Z",
     "shell.execute_reply.started": "2025-05-01T13:33:41.462703Z"
    }
   },
   "source": [
    "#Use the Function to Perform Training using Entropy\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "class_entropy = DecisionTreeClassifier(criterion='entropy', random_state=100,max_depth=3)\n",
    "\n",
    "#Create the Model\n",
    "class_entropy.fit(x_train,y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f47c27f-88d0-4f29-92a5-ae156604fcee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:37:29.958710Z",
     "iopub.status.busy": "2025-05-01T13:37:29.958319Z",
     "iopub.status.idle": "2025-05-01T13:37:29.964866Z",
     "shell.execute_reply": "2025-05-01T13:37:29.964239Z",
     "shell.execute_reply.started": "2025-05-01T13:37:29.958682Z"
    }
   },
   "source": [
    "#Make the Predictions\n",
    "y_pred = class_entropy.predict(x_test)\n",
    "print (y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62860704-5de4-414a-9774-c54ee6f6d72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T13:38:15.900396Z",
     "iopub.status.busy": "2025-05-01T13:38:15.900033Z",
     "iopub.status.idle": "2025-05-01T13:38:15.905757Z",
     "shell.execute_reply": "2025-05-01T13:38:15.905163Z",
     "shell.execute_reply.started": "2025-05-01T13:38:15.900371Z"
    }
   },
   "source": [
    "#Check for Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"The Accuracy is: \", accuracy_score(y_test,y_pred)*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1c4f1a7-c521-492f-8cd9-ef954b888a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:08:46.730362Z",
     "iopub.status.busy": "2025-05-01T14:08:46.729990Z",
     "iopub.status.idle": "2025-05-01T14:08:46.743714Z",
     "shell.execute_reply": "2025-05-01T14:08:46.743254Z",
     "shell.execute_reply.started": "2025-05-01T14:08:46.730339Z"
    }
   },
   "source": [
    "#Build a Naive Bayes classification model:\n",
    "    #Preprocess the \"Purchased\" dataset (if necessary).\n",
    "    #Split the data into training and testing sets.\n",
    "    #Train the Naive Bayes classifier.\n",
    "    #Evaluate the model's performance using accuracy, confusion matrix, and classification report.\n",
    "    #Visualize the decision boundary.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60c98fad-96ea-4dd3-85dc-d86ee172e224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:08:50.728420Z",
     "iopub.status.busy": "2025-05-01T14:08:50.728111Z",
     "iopub.status.idle": "2025-05-01T14:08:50.738886Z",
     "shell.execute_reply": "2025-05-01T14:08:50.738098Z",
     "shell.execute_reply.started": "2025-05-01T14:08:50.728398Z"
    }
   },
   "source": [
    "#Load and Preview the data in the dataset Purchase.csv into a Pandas Dataframe for analysis and modelling\n",
    "\n",
    "df = pd.read_csv(\"Purchase.csv\")\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ba48de0-9ad6-433e-ad32-ab443fc4b273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:08:53.848874Z",
     "iopub.status.busy": "2025-05-01T14:08:53.848546Z",
     "iopub.status.idle": "2025-05-01T14:08:53.852893Z",
     "shell.execute_reply": "2025-05-01T14:08:53.852093Z",
     "shell.execute_reply.started": "2025-05-01T14:08:53.848853Z"
    }
   },
   "source": [
    "#Display the number of records (rows)) and features(columns) to understand the size and dimension of the dataset\n",
    "\n",
    "print(f\"Number of records/rows: {df.shape[0]}\")\n",
    "print(f\"Number of features/columns:{df.shape[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7998964a-099a-4872-bff9-d9e1e411e4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:08:58.253010Z",
     "iopub.status.busy": "2025-05-01T14:08:58.252659Z",
     "iopub.status.idle": "2025-05-01T14:08:58.258153Z",
     "shell.execute_reply": "2025-05-01T14:08:58.257370Z",
     "shell.execute_reply.started": "2025-05-01T14:08:58.252982Z"
    }
   },
   "source": [
    "# Prepare the dataset for machine learning by splitting it into features and target variables.\n",
    "# Reshape the feature array to be compatible for Machine Learning Model Training\n",
    "# Separate the Input Variable (x), Output Variable (y) and Date\n",
    "x = df.drop(['User ID', 'Purchased'], axis =1)\n",
    "y = df['Purchased']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e916f5e3-ae02-4c46-92c5-b2ebcc8c649d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:09:02.074137Z",
     "iopub.status.busy": "2025-05-01T14:09:02.073790Z",
     "iopub.status.idle": "2025-05-01T14:09:02.090276Z",
     "shell.execute_reply": "2025-05-01T14:09:02.089568Z",
     "shell.execute_reply.started": "2025-05-01T14:09:02.074108Z"
    }
   },
   "source": [
    "#Convert labels to Number by using a labelencoder to convert gender column into Numeric Values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_gender = LabelEncoder()\n",
    "\n",
    "x['Gender_n'] = le_gender.fit_transform(x['Gender'])\n",
    "print(x.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "655993ee-174a-4b4b-873c-963e89456e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:09:05.859817Z",
     "iopub.status.busy": "2025-05-01T14:09:05.859225Z",
     "iopub.status.idle": "2025-05-01T14:09:05.865808Z",
     "shell.execute_reply": "2025-05-01T14:09:05.865232Z",
     "shell.execute_reply.started": "2025-05-01T14:09:05.859786Z"
    }
   },
   "source": [
    "#Drop the Original Gender Column\n",
    "x.drop('Gender', axis=1, inplace=True)\n",
    "print(x.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "474f814c-e234-444d-bfed-84e55b21d1f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:09:08.870979Z",
     "iopub.status.busy": "2025-05-01T14:09:08.870622Z",
     "iopub.status.idle": "2025-05-01T14:09:08.877681Z",
     "shell.execute_reply": "2025-05-01T14:09:08.877082Z",
     "shell.execute_reply.started": "2025-05-01T14:09:08.870949Z"
    }
   },
   "source": [
    "# Split the data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e6bca43-4c4b-4963-a6dd-c92c3af87509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:10:38.781503Z",
     "iopub.status.busy": "2025-05-01T14:10:38.781200Z",
     "iopub.status.idle": "2025-05-01T14:10:38.789490Z",
     "shell.execute_reply": "2025-05-01T14:10:38.789020Z",
     "shell.execute_reply.started": "2025-05-01T14:10:38.781481Z"
    }
   },
   "source": [
    "# Gaussian Naive Bayes classifier is instantiated and trained on the training data\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38fca80b-de39-48e0-bc53-c70bd9d2d131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:11:33.759844Z",
     "iopub.status.busy": "2025-05-01T14:11:33.759461Z",
     "iopub.status.idle": "2025-05-01T14:11:33.766048Z",
     "shell.execute_reply": "2025-05-01T14:11:33.765187Z",
     "shell.execute_reply.started": "2025-05-01T14:11:33.759815Z"
    }
   },
   "source": [
    "# Make predictions using the trained Gaussian Naive Bayes model and evaluate its accuracy.\n",
    "y_pred = classifier.predict(x_test) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "373c7f69-24f7-4997-8568-540ff006e566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T14:12:14.183716Z",
     "iopub.status.busy": "2025-05-01T14:12:14.183413Z",
     "iopub.status.idle": "2025-05-01T14:12:14.188800Z",
     "shell.execute_reply": "2025-05-01T14:12:14.188303Z",
     "shell.execute_reply.started": "2025-05-01T14:12:14.183696Z"
    }
   },
   "source": [
    "# The accuracy of the model is then calculated by comparing the predicted values\n",
    "accuracy_score(y_test, y_pred) \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce1ef9e3-0cf4-4ce5-a551-7886d7e6616c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:38:48.221043Z",
     "iopub.status.busy": "2025-05-01T15:38:48.220432Z",
     "iopub.status.idle": "2025-05-01T15:38:48.227286Z",
     "shell.execute_reply": "2025-05-01T15:38:48.226191Z",
     "shell.execute_reply.started": "2025-05-01T15:38:48.221010Z"
    }
   },
   "source": [
    "#Build a K-Nearest Neighbours (KNN) classification model:\n",
    "    #Preprocess the diabetes dataset (handle missing values, scale features).\n",
    "    #Split the data into training and testing sets.\n",
    "    #Train the KNN model.\n",
    "    #Evaluate the model's performance using accuracy, precision, and recall.\n",
    "#Import necessary libraries for data handling (Pandas, NumPy), model building (scikit-learn), \n",
    "# feature scaling, and model evaluation. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bceffa99-76ea-46d3-9a80-c6a7106caeb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:38:50.643191Z",
     "iopub.status.busy": "2025-05-01T15:38:50.642830Z",
     "iopub.status.idle": "2025-05-01T15:38:50.664762Z",
     "shell.execute_reply": "2025-05-01T15:38:50.663901Z",
     "shell.execute_reply.started": "2025-05-01T15:38:50.643163Z"
    }
   },
   "source": [
    "#Load and Preview the data in the dataset diabetes.csv into a Pandas Dataframe for analysis and modelling\n",
    "\n",
    "df=pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6444f215-63cd-40c8-af8c-f4f78d1f022e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:38:55.184499Z",
     "iopub.status.busy": "2025-05-01T15:38:55.184093Z",
     "iopub.status.idle": "2025-05-01T15:38:55.189030Z",
     "shell.execute_reply": "2025-05-01T15:38:55.188429Z",
     "shell.execute_reply.started": "2025-05-01T15:38:55.184468Z"
    }
   },
   "source": [
    "#Display the number of records (rows)) and features(columns) to understand the size and dimension of the dataset\n",
    "\n",
    "print(f\"Number of records/rows: {df.shape[0]}\")\n",
    "print(f\"Number of features/columns:{df.shape[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "976f86ee-87a9-422b-be46-a69fd814983a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:39:39.794327Z",
     "iopub.status.busy": "2025-05-01T15:39:39.794002Z",
     "iopub.status.idle": "2025-05-01T15:39:39.799991Z",
     "shell.execute_reply": "2025-05-01T15:39:39.799389Z",
     "shell.execute_reply.started": "2025-05-01T15:39:39.794307Z"
    }
   },
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d566e112-2099-4b87-a21f-580b65637a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:39:59.424621Z",
     "iopub.status.busy": "2025-05-01T15:39:59.424316Z",
     "iopub.status.idle": "2025-05-01T15:39:59.439034Z",
     "shell.execute_reply": "2025-05-01T15:39:59.438463Z",
     "shell.execute_reply.started": "2025-05-01T15:39:59.424601Z"
    }
   },
   "source": [
    "## Identify features where zero is medically invalid, replace zero values with NaN, \n",
    "#and then impute missing values using the mean of each feature to ensure data consistency. \n",
    "\n",
    "zero_not_accepted=[\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "for column in zero_not_accepted:\n",
    "  df[column]=df[column].replace(0, np.nan)\n",
    "  mean=int(df[column].mean(skipna=True))\n",
    "  df[column]=df[column].replace(np.nan, mean)\n",
    "  print(df[column])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49baae90-b79a-4a3b-a38c-edd0c6832e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:40:14.285144Z",
     "iopub.status.busy": "2025-05-01T15:40:14.284654Z",
     "iopub.status.idle": "2025-05-01T15:40:14.295178Z",
     "shell.execute_reply": "2025-05-01T15:40:14.294457Z",
     "shell.execute_reply.started": "2025-05-01T15:40:14.285111Z"
    }
   },
   "source": [
    "# Split dataset into Train and Test\n",
    "\n",
    "X = df.drop('Outcome', axis=1)  # Assign the features to X\n",
    "Y = df['Outcome']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff28c9af-0ad8-4673-8f2f-238a6afb5769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:40:19.453636Z",
     "iopub.status.busy": "2025-05-01T15:40:19.453250Z",
     "iopub.status.idle": "2025-05-01T15:40:19.464910Z",
     "shell.execute_reply": "2025-05-01T15:40:19.464240Z",
     "shell.execute_reply.started": "2025-05-01T15:40:19.453608Z"
    }
   },
   "source": [
    "#Feature Scaling\n",
    "# Standardize the feature values to have a mean of 0 and a standard deviation of 1, \n",
    "# improving the performance and convergence speed of machine learning algorithms like KNN. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "print(X_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0d32471-3f4b-4dae-a46a-6c0a6aec79c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T15:41:11.029596Z",
     "iopub.status.busy": "2025-05-01T15:41:11.029202Z",
     "iopub.status.idle": "2025-05-01T15:41:11.129270Z",
     "shell.execute_reply": "2025-05-01T15:41:11.127339Z",
     "shell.execute_reply.started": "2025-05-01T15:41:11.029565Z"
    }
   },
   "source": [
    "# We use the K-Nearest Neighbors (KNN) algorithm with Euclidean distance for classification.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=19, metric='euclidean')\n",
    "classifier.fit(X_train, Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(f1_score(Y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1480839-f6a0-4122-ba34-da56d82dc94d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d9f469a-b09e-4eb6-8a04-6950bf7bf4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:41:44.921055Z",
     "iopub.status.busy": "2025-05-02T06:41:44.920508Z",
     "iopub.status.idle": "2025-05-02T06:41:44.924929Z",
     "shell.execute_reply": "2025-05-02T06:41:44.924316Z",
     "shell.execute_reply.started": "2025-05-02T06:41:44.921030Z"
    }
   },
   "source": [
    "# *** PCA-2 Exam 2025 ***\n",
    "# Import Python Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import confusion_matrix \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93085cd8-c0e6-47d0-ac09-1f6bd6d592a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:48:03.065003Z",
     "iopub.status.busy": "2025-05-02T05:48:03.064446Z",
     "iopub.status.idle": "2025-05-02T05:48:03.095928Z",
     "shell.execute_reply": "2025-05-02T05:48:03.095213Z",
     "shell.execute_reply.started": "2025-05-02T05:48:03.064974Z"
    }
   },
   "source": [
    "#Load and Preview the data in the dataset Car_Data.csv into a Pandas Dataframe for analysis and modelling\n",
    "\n",
    "df = pd.read_csv(\"Car_Data.csv\")\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f13d1835-3e82-443b-b980-6bae88200be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:45:39.307186Z",
     "iopub.status.busy": "2025-05-02T06:45:39.306805Z",
     "iopub.status.idle": "2025-05-02T06:45:39.310252Z",
     "shell.execute_reply": "2025-05-02T06:45:39.309745Z",
     "shell.execute_reply.started": "2025-05-02T06:45:39.307163Z"
    }
   },
   "source": [
    "#1. Display the dimension of the dataset\n",
    "\n",
    "print(f\"Number of records/rows: {df.shape[0]}\")\n",
    "print(f\"Number of features/columns:{df.shape[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f9df1a1-0be1-4505-8f05-d44078c74b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:49:57.651523Z",
     "iopub.status.busy": "2025-05-02T05:49:57.651135Z",
     "iopub.status.idle": "2025-05-02T05:49:57.663399Z",
     "shell.execute_reply": "2025-05-02T05:49:57.662869Z",
     "shell.execute_reply.started": "2025-05-02T05:49:57.651492Z"
    }
   },
   "source": [
    "# 2. Display top 10 rows of the dataset\n",
    "\n",
    "df = pd.read_csv(\"Car_Data.csv\")\n",
    "df.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40da07cd-f2db-4c2c-9a5d-796cf4df0574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:51:59.430736Z",
     "iopub.status.busy": "2025-05-02T05:51:59.430418Z",
     "iopub.status.idle": "2025-05-02T05:51:59.445849Z",
     "shell.execute_reply": "2025-05-02T05:51:59.445264Z",
     "shell.execute_reply.started": "2025-05-02T05:51:59.430715Z"
    }
   },
   "source": [
    "\n",
    "# 3. Display the summary of the dataset\n",
    "summary = df.describe()\n",
    "\n",
    "print(summary)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c781032a-4db7-4700-a8e5-5d867a6f4995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:54:39.860404Z",
     "iopub.status.busy": "2025-05-02T05:54:39.860120Z",
     "iopub.status.idle": "2025-05-02T05:54:39.868863Z",
     "shell.execute_reply": "2025-05-02T05:54:39.868287Z",
     "shell.execute_reply.started": "2025-05-02T05:54:39.860383Z"
    }
   },
   "source": [
    "# 4. Display the frequency distribution of the value in the variable “Buying” \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Display the frequency distribution of the value in the variable 'Buying'\n",
    "frequency_distribution = df['Buying'].value_counts()\n",
    "\n",
    "print(frequency_distribution)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a02bda6e-69ab-4841-8d86-ba456c109e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:56:43.381204Z",
     "iopub.status.busy": "2025-05-02T05:56:43.380961Z",
     "iopub.status.idle": "2025-05-02T05:56:43.388515Z",
     "shell.execute_reply": "2025-05-02T05:56:43.387994Z",
     "shell.execute_reply.started": "2025-05-02T05:56:43.381187Z"
    }
   },
   "source": [
    "# 5. Display the count of missing values in each variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Display the count of missing values in each variable\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "print(missing_values_count)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e56875c-fc31-42d3-bd67-e72e7ec21ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T05:59:48.032928Z",
     "iopub.status.busy": "2025-05-02T05:59:48.032562Z",
     "iopub.status.idle": "2025-05-02T05:59:49.754510Z",
     "shell.execute_reply": "2025-05-02T05:59:49.753809Z",
     "shell.execute_reply.started": "2025-05-02T05:59:48.032901Z"
    }
   },
   "source": [
    "# 6. Visualize the number of the classes for each buying category through a countplot\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Create a countplot to visualize the number of classes for each buying category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Buying', hue='Class')\n",
    "plt.title('Number of Classes for Each Buying Category')\n",
    "plt.xlabel('Buying Category')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Class')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8d90548-2760-4b3c-ae9e-1e7a9a2dee8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:03:00.338908Z",
     "iopub.status.busy": "2025-05-02T06:03:00.338643Z",
     "iopub.status.idle": "2025-05-02T06:03:00.349287Z",
     "shell.execute_reply": "2025-05-02T06:03:00.348609Z",
     "shell.execute_reply.started": "2025-05-02T06:03:00.338887Z"
    }
   },
   "source": [
    "# 7. Segregate the input features and target/output variable in 2 different variables (X,Y) \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "print(\"Input Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget/Output Variable (Y):\")\n",
    "print(Y.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de6cc4b5-2f53-43ee-aac6-3c96b3b72708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:08:05.006761Z",
     "iopub.status.busy": "2025-05-02T06:08:05.005037Z",
     "iopub.status.idle": "2025-05-02T06:08:05.035897Z",
     "shell.execute_reply": "2025-05-02T06:08:05.034936Z",
     "shell.execute_reply.started": "2025-05-02T06:08:05.006717Z"
    }
   },
   "source": [
    "# 8. Split data into training set and testing set (40%)\n",
    "# Split dataset into Train and Test\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "# Split data into training set (60%) and testing set (40%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "print(\"Training Set:\")\n",
    "print(X_train.head())\n",
    "print(Y_train.head())\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(X_test.head())\n",
    "print(Y_test.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e406574-8843-45ca-8e4c-2de8e4183672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:10:34.178411Z",
     "iopub.status.busy": "2025-05-02T06:10:34.178014Z",
     "iopub.status.idle": "2025-05-02T06:10:34.195645Z",
     "shell.execute_reply": "2025-05-02T06:10:34.194974Z",
     "shell.execute_reply.started": "2025-05-02T06:10:34.178392Z"
    }
   },
   "source": [
    "# 9. Transform the values of X_train and X_test to numeric representations\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "# Split data into training set (60%) and testing set (40%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform the values of X_train and X_test to numeric representations\n",
    "X_train_encoded = X_train.apply(label_encoder.fit_transform)\n",
    "X_test_encoded = X_test.apply(label_encoder.fit_transform)\n",
    "\n",
    "print(\"Transformed Training Set:\")\n",
    "print(X_train_encoded.head())\n",
    "\n",
    "print(\"\\nTransformed Testing Set:\")\n",
    "print(X_test_encoded.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418cab09-4af5-4bd0-a00c-56b64c108164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:00:44.305469Z",
     "iopub.status.busy": "2025-05-02T07:00:44.304919Z",
     "iopub.status.idle": "2025-05-02T07:00:44.322809Z",
     "shell.execute_reply": "2025-05-02T07:00:44.322306Z",
     "shell.execute_reply.started": "2025-05-02T07:00:44.305448Z"
    }
   },
   "source": [
    "# 10. Create a decision tree model with “Entropy” as the model criterion\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "# Split data into training set (60%) and testing set (40%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform the values of X_train and X_test to numeric representations\n",
    "X_train_encoded = X_train.apply(label_encoder.fit_transform)\n",
    "X_test_encoded = X_test.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Create a decision tree model with \"Entropy\" as the model criterion\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Train the model\n",
    "decision_tree_model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "print(\"Decision Tree Model created with 'Entropy' as the model criterion.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bde4cdef-5ede-4641-b5ee-176875fa9c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:21:14.374024Z",
     "iopub.status.busy": "2025-05-02T06:21:14.373664Z",
     "iopub.status.idle": "2025-05-02T06:21:14.391047Z",
     "shell.execute_reply": "2025-05-02T06:21:14.390530Z",
     "shell.execute_reply.started": "2025-05-02T06:21:14.373987Z"
    }
   },
   "source": [
    "# 11. Train the model with training dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "# Split data into training set (60%) and testing set (40%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform the values of X_train and X_test to numeric representations\n",
    "X_train_encoded = X_train.apply(label_encoder.fit_transform)\n",
    "X_test_encoded = X_test.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Create a decision tree model with \"Entropy\" as the model criterion\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Train the model with training dataset\n",
    "decision_tree_model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "print(\"Model trained with training dataset.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe1e2e52-e2f1-4b7c-bc2f-de610aa15b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:37:22.395607Z",
     "iopub.status.busy": "2025-05-02T06:37:22.395350Z",
     "iopub.status.idle": "2025-05-02T06:37:22.595023Z",
     "shell.execute_reply": "2025-05-02T06:37:22.594377Z",
     "shell.execute_reply.started": "2025-05-02T06:37:22.395588Z"
    }
   },
   "source": [
    "# 12. Predict the test set using the model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier()  # You may want to add parameters here\n",
    "\n",
    "# Train the model (assuming X_train_encoded and y_train are already defined)\n",
    "clf.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# 12. Predict the test set using the model\n",
    "y_predict = clf.predict(X_test_encoded)\n",
    "#print (y_predict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "567a9b75-2171-4914-8e30-a1546661f904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:39:48.796335Z",
     "iopub.status.busy": "2025-05-02T06:39:48.796029Z",
     "iopub.status.idle": "2025-05-02T06:39:48.815604Z",
     "shell.execute_reply": "2025-05-02T06:39:48.815051Z",
     "shell.execute_reply.started": "2025-05-02T06:39:48.796312Z"
    }
   },
   "source": [
    "# 13. Check the accuracy of the model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Car_Data.csv')\n",
    "\n",
    "# Segregate the input features (X) and target/output variable (Y)\n",
    "X = df.drop(columns=['Class'])\n",
    "Y = df['Class']\n",
    "\n",
    "# Split data into training set (60%) and testing set (40%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform the values of X_train and X_test to numeric representations\n",
    "X_train_encoded = X_train.apply(label_encoder.fit_transform)\n",
    "X_test_encoded = X_test.apply(label_encoder.fit_transform)\n",
    "\n",
    "# Create a decision tree model with \"Entropy\" as the model criterion\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Train the model with training dataset\n",
    "decision_tree_model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Predict the test set using the model\n",
    "Y_pred = decision_tree_model.predict(X_test_encoded)\n",
    "\n",
    "# Check the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Accuracy of the model: {accuracy * 100:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f57f4eed-e389-4221-a3fa-84e3d733dc14",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
